{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92308592",
   "metadata": {},
   "source": [
    "# üîç Inference with Saved State-LSTM + Random Forest Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639ed267",
   "metadata": {},
   "source": [
    "This notebook loads previously saved state-based LSTM models, detects anomalies, and classifies the detected anomalies using a pre-trained Random Forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86e3da2",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d53ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaa633c",
   "metadata": {},
   "source": [
    "## üì• Step 2: Load and Prepare Reshaped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21021f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"../test_csv/motor_monitor_0_reshaped.csv\")\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1753b696",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Step 3: Define Sliding Window Anomaly Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd5ec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_sequences(data, seq_length=30):\n",
    "    return np.array([data.iloc[i:i+seq_length].values for i in range(len(data)-seq_length)])\n",
    "\n",
    "def detect_state_anomalies(df_state, model_path, feature_cols):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled = scaler.fit_transform(df_state[feature_cols])\n",
    "    sequences = create_sequences(pd.DataFrame(scaled))\n",
    "    \n",
    "    model = load_model(model_path)\n",
    "    reconstructions = model.predict(sequences)\n",
    "    errors = np.mean((reconstructions - sequences) ** 2, axis=(1, 2))\n",
    "    \n",
    "    threshold = np.percentile(errors, 95)\n",
    "    print(f\"Threshold for {model_path}: {threshold:.6f}\")\n",
    "    \n",
    "    flags = np.array([False] * len(df_state))\n",
    "    flags[30:len(errors)+30] = errors > threshold\n",
    "    df_state['reconstruction_error'] = [0.0]*30 + errors.tolist()\n",
    "    df_state['is_anomaly'] = flags\n",
    "    return df_state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735ca3ce",
   "metadata": {},
   "source": [
    "## üß† Step 4: Apply Detection by State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6fe9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_all = pd.DataFrame()\n",
    "feature_cols = ['power', 'rpm', 'temperature', 'vibration']\n",
    "model_paths = {\n",
    "    'run': \"../test_cases/saved_models/lstm_run.h5\",\n",
    "    'idle': \"../test_cases/saved_models/lstm_idle.h5\",\n",
    "    'off': \"../test_cases/saved_models/lstm_off.h5\"\n",
    "}\n",
    "\n",
    "for state in df['state'].unique():\n",
    "    df_state = df[df['state'] == state].copy()\n",
    "    model_path = model_paths.get(state)\n",
    "    if model_path:\n",
    "        df_state = detect_state_anomalies(df_state, model_path, feature_cols)\n",
    "        df_all = pd.concat([df_all, df_state])\n",
    "df = df_all.sort_values('timestamp').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5397d301",
   "metadata": {},
   "source": [
    "## ü§ñ Step 5: Classify Detected Anomalies with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c356f683",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# One-hot encode state to match training\n",
    "df_encoded = pd.get_dummies(df, columns=[\"state\"])\n",
    "for col in [\"state_off\", \"state_run\", \"state_idle\"]:\n",
    "    if col not in df_encoded.columns:\n",
    "        df_encoded[col] = 0\n",
    "\n",
    "# Load RF model\n",
    "rf_model = joblib.load(\"../test_cases/saved_models/random_forest.pkl\")\n",
    "\n",
    "# Filter anomaly rows\n",
    "anomaly_df = df_encoded[df_encoded[\"is_anomaly\"] == True].copy()\n",
    "features = ['power', 'rpm', 'temperature', 'vibration', 'state_off', 'state_run', 'state_idle']\n",
    "\n",
    "# Evaluate\n",
    "if 'label' in anomaly_df.columns:\n",
    "    X_anomaly = anomaly_df[features]\n",
    "    y_true = anomaly_df['label']\n",
    "    y_pred = rf_model.predict(X_anomaly)\n",
    "    \n",
    "    print(\"üîç Classification Report (for detected anomalies):\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è 'label' column not found. Cannot compute classification report.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
